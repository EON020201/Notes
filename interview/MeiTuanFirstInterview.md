# 美团-大模型算法实习生-面试经历-一面

## 一、项目问题

**1.我看到你有从零实现 LLAMA2 的经验，你能简单说说吗？**

答：背景是我毕设方向和大模型有关，想从 0 实现模型结构和训练过程，锻炼动手能力。问题在于它和之前常见的 Transformer 架构模型不一样，LLAMA2 在 Transformer 块基础上做了改进。比如在输入数据到注意力层之前的编码信息上做了创新，用旋转矩阵编码，作用在注意力层的 q 和 k 矩阵上，实现相对位置权重更新。传统的 Transformer 模块用 layernorm 做归一化，LLAMA2 架构用了一种简化方式，省略了 layernorm 里减去均值的操作，减少计算量，提升训练效率，大概就是这些。

**2.你当时为什么想到自己去实现，而不是用现成的模型？**

答：因为现在在 huggingface 上能直接下载模型参数、权重和结构，下载后还能直接调用 API 。但这样不太清楚模型内部运作，我从 0 实现的话，能更了解模型结构，对后续工作有帮助。

**3.网上有很多开源的训练代码，比如 LLAMA2 本身有个 model library，你觉得你做的和它最大的差异在哪？**

答：最大差异是我在本地训练，电脑算力不够，建的模型比较小。网上下载的模型，哪怕是最小参数量的，都比我本地部署的大很多。所以我的模型输出的推理结果肯定没网上下载的好。

**4.你怎么判断自己的实现是正确的，而不是中间某些地方出了问题？怎么判断自己写的函数对不对？**

答：判断的话…… 我还真没仔细判断过，就是在训练过程中看 loss，看训练曲线是不是接近 0，用训练好的权重做了一次推理。我看推理结果不是乱七八糟的，感觉训练得还可以。

**5.开发一般要有明确目的，做这样的探索很好，但你也得考虑，比如有些函数可以通过输入输出，对比自己和官方实现的差异。要是能围绕这个做更深入分析就更好了。就像你说的，大多数人电脑跑不了相关训练，这时候验证自己实现的函数，分析实现上的差异，是挺好的。我看到你还有 qwen 2.5 本地部署调用和 Lora 微调的项目，讲讲这个。**

答：做这个项目主要是想熟悉 Lora 微调过程，我用 PEFT 库直接调用 Lora 参数和接口去训练，用了开源数据集，这样能熟悉流程。前面做过预训练，这次想尝试监督微调。先是找了个中文法律开源数据集，规模不大，大概几万条文本，从魔搭平台下载了 7B 模型，再用 PEFT 库调 Lora 方法，设置超参数，像 Lora 的秩、权重系数，还有作用在哪些层、哪些权重矩阵上这些。设置好后训练，训练完加载模型，输入一些法律相关问题，模型能正确回答，就是这样一个过程。

**6.评价大模型是个有挑战的事，你刚刚举的例子主要是看实际案例。你对怎么评价不同方式训练出的大模型哪个效果更好，有什么想法吗？在你实践的场景里，更多是看训练好的模型输入输出。你有没有考虑过用其他方式评价训练出的模型效果？**

答：我具体没尝试过，如果要做的话，应该是找一些有验证集的公开数据集，在上面跑分，对比自己模型和其他模型的分数。

**7.除了这两个项目，还有其他和大模型相关的项目可以简单介绍下吗？**

答：没有了。

**8.能用 Python 实现链表或者二叉树吗？**

答：直接手写，定义一个类就行，是吧？

**9.二叉树和链表，你选一个。**

答：链表。

## 二、代码题目

**1.给你链表的头节点 head ，每 k 个节点一组进行翻转，请你返回修改后的链表。k 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换。**

答案：https://leetcode.cn/problems/reverse-nodes-in-k-group/description/